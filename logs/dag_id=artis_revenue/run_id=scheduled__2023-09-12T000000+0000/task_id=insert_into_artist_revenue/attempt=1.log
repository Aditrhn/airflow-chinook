[2023-09-13T12:14:55.930+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: artis_revenue.insert_into_artist_revenue scheduled__2023-09-12T00:00:00+00:00 [queued]>
[2023-09-13T12:14:55.940+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: artis_revenue.insert_into_artist_revenue scheduled__2023-09-12T00:00:00+00:00 [queued]>
[2023-09-13T12:14:55.940+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2023-09-13T12:14:56.048+0000] {taskinstance.py:1382} INFO - Executing <Task(GenericTransfer): insert_into_artist_revenue> on 2023-09-12 00:00:00+00:00
[2023-09-13T12:14:56.055+0000] {standard_task_runner.py:57} INFO - Started process 71 to run task
[2023-09-13T12:14:56.061+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'artis_revenue', 'insert_into_artist_revenue', 'scheduled__2023-09-12T00:00:00+00:00', '--job-id', '152', '--raw', '--subdir', 'DAGS_FOLDER/artist_revenue.py', '--cfg-path', '/tmp/tmpc3omz9yd']
[2023-09-13T12:14:56.064+0000] {standard_task_runner.py:85} INFO - Job 152: Subtask insert_into_artist_revenue
[2023-09-13T12:14:56.161+0000] {task_command.py:415} INFO - Running <TaskInstance: artis_revenue.insert_into_artist_revenue scheduled__2023-09-12T00:00:00+00:00 [running]> on host bdff3168b881
[2023-09-13T12:14:56.269+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Aditiya Rahman' AIRFLOW_CTX_DAG_ID='artis_revenue' AIRFLOW_CTX_TASK_ID='insert_into_artist_revenue' AIRFLOW_CTX_EXECUTION_DATE='2023-09-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-09-12T00:00:00+00:00'
[2023-09-13T12:14:56.282+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-13T12:14:56.305+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-13T12:14:56.306+0000] {generic_transfer.py:77} INFO - Extracting data from postgres
[2023-09-13T12:14:56.306+0000] {generic_transfer.py:78} INFO - Executing: 
 
SELECT a."ArtistId", 
       a."Name", 
       b."Title", 
       c."Name", 
       (d."Quantity" * d."UnitPrice"),
       d."InvoiceLineId",
       e."InvoiceId",
       e."InvoiceDate"
FROM "Artist" a
JOIN "Album" b
ON a."ArtistId" = b."ArtistId"
JOIN "Track" c
ON b."AlbumId" = c."AlbumId"
JOIN "InvoiceLine" d
ON c."TrackId" = d."TrackId"
JOIN "Invoice" e
ON d."InvoiceId" = e."InvoiceId"
[2023-09-13T12:14:56.313+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-13T12:14:56.316+0000] {sql.py:418} INFO - Running statement: 
SELECT a."ArtistId", 
       a."Name", 
       b."Title", 
       c."Name", 
       (d."Quantity" * d."UnitPrice"),
       d."InvoiceLineId",
       e."InvoiceId",
       e."InvoiceDate"
FROM "Artist" a
JOIN "Album" b
ON a."ArtistId" = b."ArtistId"
JOIN "Track" c
ON b."AlbumId" = c."AlbumId"
JOIN "InvoiceLine" d
ON c."TrackId" = d."TrackId"
JOIN "Invoice" e
ON d."InvoiceId" = e."InvoiceId", parameters: None
[2023-09-13T12:14:56.328+0000] {sql.py:427} INFO - Rows affected: 2240
[2023-09-13T12:14:56.337+0000] {generic_transfer.py:95} INFO - Running preoperator
[2023-09-13T12:14:56.338+0000] {generic_transfer.py:96} INFO - ['DROP TABLE IF EXISTS artist_revenue', '\n        CREATE TABLE artist_revenue (\n        "ArtistId" INT NOT NULL,\n        "ArtistName" VARCHAR(120),\n        "AlbumTitle" VARCHAR(160) NOT NULL,\n        "TrackName" VARCHAR(200) NOT NULL,\n        "TotalPrice" NUMERIC(10,2) NOT NULL,\n        "InvoiceLineId" INT NOT NULL,\n        "InvoiceId" INT NOT NULL,\n        "InvoiceDate" TIMESTAMP NOT NULL)\n        ']
[2023-09-13T12:14:56.343+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-13T12:14:56.345+0000] {sql.py:418} INFO - Running statement: DROP TABLE IF EXISTS artist_revenue, parameters: None
[2023-09-13T12:14:56.352+0000] {sql.py:418} INFO - Running statement: 
        CREATE TABLE artist_revenue (
        "ArtistId" INT NOT NULL,
        "ArtistName" VARCHAR(120),
        "AlbumTitle" VARCHAR(160) NOT NULL,
        "TrackName" VARCHAR(200) NOT NULL,
        "TotalPrice" NUMERIC(10,2) NOT NULL,
        "InvoiceLineId" INT NOT NULL,
        "InvoiceId" INT NOT NULL,
        "InvoiceDate" TIMESTAMP NOT NULL)
        , parameters: None
[2023-09-13T12:14:56.373+0000] {generic_transfer.py:105} INFO - Inserting rows into datawarehouse
[2023-09-13T12:14:56.379+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-13T12:14:56.585+0000] {sql.py:512} INFO - Loaded 1000 rows into artist_revenue so far
[2023-09-13T12:14:56.771+0000] {sql.py:512} INFO - Loaded 2000 rows into artist_revenue so far
[2023-09-13T12:14:56.839+0000] {sql.py:515} INFO - Done loading. Loaded a total of 2240 rows into artist_revenue
[2023-09-13T12:14:56.852+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=artis_revenue, task_id=insert_into_artist_revenue, execution_date=20230912T000000, start_date=20230913T121455, end_date=20230913T121456
[2023-09-13T12:14:56.917+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2023-09-13T12:14:56.969+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
