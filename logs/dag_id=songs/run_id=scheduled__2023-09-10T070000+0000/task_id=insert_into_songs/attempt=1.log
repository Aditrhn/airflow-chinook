[2023-09-11T14:02:56.245+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: songs.insert_into_songs scheduled__2023-09-10T07:00:00+00:00 [queued]>
[2023-09-11T14:02:56.250+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: songs.insert_into_songs scheduled__2023-09-10T07:00:00+00:00 [queued]>
[2023-09-11T14:02:56.251+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2023-09-11T14:02:56.261+0000] {taskinstance.py:1382} INFO - Executing <Task(GenericTransfer): insert_into_songs> on 2023-09-10 07:00:00+00:00
[2023-09-11T14:02:56.267+0000] {standard_task_runner.py:57} INFO - Started process 725 to run task
[2023-09-11T14:02:56.269+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'songs', 'insert_into_songs', 'scheduled__2023-09-10T07:00:00+00:00', '--job-id', '122', '--raw', '--subdir', 'DAGS_FOLDER/songs.py', '--cfg-path', '/tmp/tmpfdzrzuqf']
[2023-09-11T14:02:56.271+0000] {standard_task_runner.py:85} INFO - Job 122: Subtask insert_into_songs
[2023-09-11T14:02:56.312+0000] {task_command.py:415} INFO - Running <TaskInstance: songs.insert_into_songs scheduled__2023-09-10T07:00:00+00:00 [running]> on host 80a7ead3f1b6
[2023-09-11T14:02:56.374+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Aditiya Rahman' AIRFLOW_CTX_DAG_ID='songs' AIRFLOW_CTX_TASK_ID='insert_into_songs' AIRFLOW_CTX_EXECUTION_DATE='2023-09-10T07:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-09-10T07:00:00+00:00'
[2023-09-11T14:02:56.380+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-11T14:02:56.391+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:02:56.392+0000] {generic_transfer.py:77} INFO - Extracting data from postgres
[2023-09-11T14:02:56.392+0000] {generic_transfer.py:78} INFO - Executing: 
 
SELECT a."ArtistId", 
       a."Name", 
       b."AlbumId",
       b."Title",
       c."TrackId", 
       c."Name", 
       c."UnitPrice",
       c."Bytes",
       d."GenreId",
       d."Name"
FROM "Artist" a
JOIN "Album" b
ON a."ArtistId" = b."ArtistId"
JOIN "Track" c
ON b."AlbumId" = c."AlbumId"
JOIN "Genre" d
ON c."GenreId" = d."GenreId"
[2023-09-11T14:02:56.395+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-11T14:02:56.397+0000] {sql.py:418} INFO - Running statement: 
SELECT a."ArtistId", 
       a."Name", 
       b."AlbumId",
       b."Title",
       c."TrackId", 
       c."Name", 
       c."UnitPrice",
       c."Bytes",
       d."GenreId",
       d."Name"
FROM "Artist" a
JOIN "Album" b
ON a."ArtistId" = b."ArtistId"
JOIN "Track" c
ON b."AlbumId" = c."AlbumId"
JOIN "Genre" d
ON c."GenreId" = d."GenreId", parameters: None
[2023-09-11T14:02:56.404+0000] {sql.py:427} INFO - Rows affected: 3503
[2023-09-11T14:02:56.409+0000] {generic_transfer.py:95} INFO - Running preoperator
[2023-09-11T14:02:56.409+0000] {generic_transfer.py:96} INFO - ['DROP TABLE IF EXISTS songs', '\n        CREATE TABLE songs (\n        "ArtistId" INT NOT NULL,\n        "ArtistName" VARCHAR(120),\n        "AlbumId" INT NOT NULL,\n        "AlbumTitle" VARCHAR(160) NOT NULL,\n        "TrackId" INT NOT NULL,\n        "TrackName" VARCHAR(200) NOT NULL,\n        "TrackUnitPrice" NUMERIC(10,2) NOT NULL,\n        "TrackBytes" INT,\n        "GenreId" INT NOT NULL,\n        "GenreName" VARCHAR(120)\n        )\n        ']
[2023-09-11T14:02:56.413+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:02:56.415+0000] {sql.py:418} INFO - Running statement: DROP TABLE IF EXISTS songs, parameters: None
[2023-09-11T14:02:56.417+0000] {sql.py:418} INFO - Running statement: 
        CREATE TABLE songs (
        "ArtistId" INT NOT NULL,
        "ArtistName" VARCHAR(120),
        "AlbumId" INT NOT NULL,
        "AlbumTitle" VARCHAR(160) NOT NULL,
        "TrackId" INT NOT NULL,
        "TrackName" VARCHAR(200) NOT NULL,
        "TrackUnitPrice" NUMERIC(10,2) NOT NULL,
        "TrackBytes" INT,
        "GenreId" INT NOT NULL,
        "GenreName" VARCHAR(120)
        )
        , parameters: None
[2023-09-11T14:02:56.432+0000] {generic_transfer.py:105} INFO - Inserting rows into datawarehouse
[2023-09-11T14:02:56.436+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:02:56.548+0000] {sql.py:512} INFO - Loaded 1000 rows into songs so far
[2023-09-11T14:02:56.658+0000] {sql.py:512} INFO - Loaded 2000 rows into songs so far
[2023-09-11T14:02:56.770+0000] {sql.py:512} INFO - Loaded 3000 rows into songs so far
[2023-09-11T14:02:56.828+0000] {sql.py:515} INFO - Done loading. Loaded a total of 3503 rows into songs
[2023-09-11T14:02:56.836+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=songs, task_id=insert_into_songs, execution_date=20230910T070000, start_date=20230911T140256, end_date=20230911T140256
[2023-09-11T14:02:56.882+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2023-09-11T14:02:56.892+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
