[2023-09-11T14:18:53.881+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: transactions.insert_into_transactions scheduled__2023-09-11T11:00:00+00:00 [queued]>
[2023-09-11T14:18:53.886+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: transactions.insert_into_transactions scheduled__2023-09-11T11:00:00+00:00 [queued]>
[2023-09-11T14:18:53.886+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2023-09-11T14:18:53.896+0000] {taskinstance.py:1382} INFO - Executing <Task(GenericTransfer): insert_into_transactions> on 2023-09-11 11:00:00+00:00
[2023-09-11T14:18:53.900+0000] {standard_task_runner.py:57} INFO - Started process 170 to run task
[2023-09-11T14:18:53.902+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'transactions', 'insert_into_transactions', 'scheduled__2023-09-11T11:00:00+00:00', '--job-id', '125', '--raw', '--subdir', 'DAGS_FOLDER/transactions.py', '--cfg-path', '/tmp/tmput1a700m']
[2023-09-11T14:18:53.903+0000] {standard_task_runner.py:85} INFO - Job 125: Subtask insert_into_transactions
[2023-09-11T14:18:53.932+0000] {task_command.py:415} INFO - Running <TaskInstance: transactions.insert_into_transactions scheduled__2023-09-11T11:00:00+00:00 [running]> on host bdff3168b881
[2023-09-11T14:18:53.983+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Aditiya Rahman' AIRFLOW_CTX_DAG_ID='transactions' AIRFLOW_CTX_TASK_ID='insert_into_transactions' AIRFLOW_CTX_EXECUTION_DATE='2023-09-11T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-09-11T11:00:00+00:00'
[2023-09-11T14:18:53.988+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-11T14:18:54.022+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:18:54.023+0000] {generic_transfer.py:77} INFO - Extracting data from postgres
[2023-09-11T14:18:54.023+0000] {generic_transfer.py:78} INFO - Executing: 
 
SELECT a."TrackId",
       b."InvoiceId",
       d."CustomerId",
       c."InvoiceDate",
       c."Total",
       concat(d."FirstName", ' ', d."LastName"),
       d."Address",
       d."City",
       d."State",
       d."Country",
       d."PostalCode",
       d."Email"
FROM "Track" a 
JOIN "InvoiceLine" b
ON  a."TrackId" = b."TrackId"
JOIN "Invoice" c
ON  b."InvoiceId" = c."InvoiceId"
JOIN "Customer" d
ON c."CustomerId" = d."CustomerId"
[2023-09-11T14:18:54.026+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-09-11T14:18:54.028+0000] {sql.py:418} INFO - Running statement: 
SELECT a."TrackId",
       b."InvoiceId",
       d."CustomerId",
       c."InvoiceDate",
       c."Total",
       concat(d."FirstName", ' ', d."LastName"),
       d."Address",
       d."City",
       d."State",
       d."Country",
       d."PostalCode",
       d."Email"
FROM "Track" a 
JOIN "InvoiceLine" b
ON  a."TrackId" = b."TrackId"
JOIN "Invoice" c
ON  b."InvoiceId" = c."InvoiceId"
JOIN "Customer" d
ON c."CustomerId" = d."CustomerId", parameters: None
[2023-09-11T14:18:54.035+0000] {sql.py:427} INFO - Rows affected: 2240
[2023-09-11T14:18:54.038+0000] {generic_transfer.py:95} INFO - Running preoperator
[2023-09-11T14:18:54.038+0000] {generic_transfer.py:96} INFO - ['DROP TABLE IF EXISTS transactions', '\n        CREATE TABLE transactions (\n        "TrackId" INT NOT NULL,\n        "InvoiceId" INT NOT NULL,\n        "CustomerId" INT NOT NULL,\n        "InvoiceDate" TIMESTAMP NOT NULL,\n        "Total" NUMERIC(10,2) NOT NULL,\n        "FullName" VARCHAR(50) NOT NULL,\n        "Address" VARCHAR(70),\n        "City" VARCHAR(40),\n        "State" VARCHAR(40),\n        "Country" VARCHAR(40),\n        "PostalCode" VARCHAR(10),\n        "Email" VARCHAR(60) NOT NULL\n        )\n        ']
[2023-09-11T14:18:54.042+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:18:54.044+0000] {sql.py:418} INFO - Running statement: DROP TABLE IF EXISTS transactions, parameters: None
[2023-09-11T14:18:54.046+0000] {sql.py:418} INFO - Running statement: 
        CREATE TABLE transactions (
        "TrackId" INT NOT NULL,
        "InvoiceId" INT NOT NULL,
        "CustomerId" INT NOT NULL,
        "InvoiceDate" TIMESTAMP NOT NULL,
        "Total" NUMERIC(10,2) NOT NULL,
        "FullName" VARCHAR(50) NOT NULL,
        "Address" VARCHAR(70),
        "City" VARCHAR(40),
        "State" VARCHAR(40),
        "Country" VARCHAR(40),
        "PostalCode" VARCHAR(10),
        "Email" VARCHAR(60) NOT NULL
        )
        , parameters: None
[2023-09-11T14:18:54.053+0000] {generic_transfer.py:105} INFO - Inserting rows into datawarehouse
[2023-09-11T14:18:54.056+0000] {base.py:73} INFO - Using connection ID 'datawarehouse' for task execution.
[2023-09-11T14:18:54.175+0000] {sql.py:512} INFO - Loaded 1000 rows into transactions so far
[2023-09-11T14:18:54.289+0000] {sql.py:512} INFO - Loaded 2000 rows into transactions so far
[2023-09-11T14:18:54.319+0000] {sql.py:515} INFO - Done loading. Loaded a total of 2240 rows into transactions
[2023-09-11T14:18:54.326+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=transactions, task_id=insert_into_transactions, execution_date=20230911T110000, start_date=20230911T141853, end_date=20230911T141854
[2023-09-11T14:18:54.355+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2023-09-11T14:18:54.366+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
